{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some stuff, not sure what we will need yet\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading Training CSV data\n",
    "train=pd.read_csv(\"sign_mnist_train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>138</td>\n",
       "      <td>148</td>\n",
       "      <td>127</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>96</td>\n",
       "      <td>106</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>128</td>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>104</td>\n",
       "      <td>194</td>\n",
       "      <td>183</td>\n",
       "      <td>186</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "      <td>135</td>\n",
       "      <td>143</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>166</td>\n",
       "      <td>242</td>\n",
       "      <td>227</td>\n",
       "      <td>230</td>\n",
       "      <td>227</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "      <td>209</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>248</td>\n",
       "      <td>247</td>\n",
       "      <td>248</td>\n",
       "      <td>253</td>\n",
       "      <td>236</td>\n",
       "      <td>230</td>\n",
       "      <td>240</td>\n",
       "      <td>253</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>191</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>199</td>\n",
       "      <td>201</td>\n",
       "      <td>202</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      6     149     149     150     150     150     151     151     150   \n",
       "1      5     126     128     131     132     133     134     135     135   \n",
       "2     10      85      88      92      96     105     123     135     143   \n",
       "3      0     203     205     207     206     207     209     210     209   \n",
       "4      3     188     191     193     195     199     201     202     203   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     151  ...       138       148       127        89        82        96   \n",
       "1     136  ...        47       104       194       183       186       184   \n",
       "2     147  ...        68       166       242       227       230       227   \n",
       "3     210  ...       154       248       247       248       253       236   \n",
       "4     203  ...        26        40        64        48        29        46   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       106       112       120       107  \n",
       "1       184       184       182       180  \n",
       "2       226       225       224       222  \n",
       "3       230       240       253       255  \n",
       "4        49        46        46        53  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading Testing CSV data\n",
    "test=pd.read_csv(\"sign_mnist_test.csv\")\n",
    "print(train.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we must seperate the labels from the data\n",
    "label_train=train[\"label\"]\n",
    "label_test=test[\"label\"]\n",
    "\n",
    "img_train=train.drop(['label'],axis=1)\n",
    "img_test=test.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing what a random image looks like in the dataset to ensure accuracy\n",
    "sampImg = random.randint(0,len(img_train.index))\n",
    "fig, ax = plt.subplots()\n",
    "i=img_train.iloc[sampImg].to_numpy()\n",
    "i=i.reshape((28,28))\n",
    "ax.imshow(i, cmap = 'gray')\n",
    "ax.set_xlabel(label_train.iloc[sampImg])\n",
    "plt.show()\n",
    "\n",
    "#A=0\n",
    "#B=1\n",
    "#C=2\n",
    "#etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the image data into a MNIST type format\n",
    "train_images = img_train.values.reshape(-1,28,28,1)\n",
    "test_images = img_test.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing label data\n",
    "labels = to_categorical(label_train, num_classes = 25)\n",
    "labels_test = to_categorical(label_test, num_classes = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (24709, 28, 28, 1)\n",
      "x_test shape (2746, 28, 28, 1)\n",
      "y_train shape (24709, 25)\n",
      "y_test shape (2746, 25)\n"
     ]
    }
   ],
   "source": [
    "#splitting training data to such that we can use the validation dataset for post model metrics lice confusion matrix\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_images, labels, test_size=0.10, random_state=69)\n",
    "\n",
    "print(\"x_train shape\",X_train.shape)\n",
    "print(\"x_test shape\",X_val.shape)\n",
    "print(\"y_train shape\",Y_train.shape)\n",
    "print(\"y_test shape\",Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating more data using image data generator (this will be used late, just setting it up)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1\n",
    ")\n",
    "\n",
    "train_data = datagen.flow(X_train, Y_train, batch_size = 128)\n",
    "test_data = datagen.flow(X_val, Y_val, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 100)       2600      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 50)        45050     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 10)        4510      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 7, 7, 10)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 490)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 500)               245500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               50100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 25)                2525      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 350285 (1.34 MB)\n",
      "Trainable params: 350285 (1.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture.\n",
    "model = tf.keras.models.Sequential([\n",
    "    layers.Conv2D(100, (5, 5), activation = 'relu', padding = 'same', input_shape = (28, 28, 1)),\n",
    "    layers.Conv2D(50, (3, 3), activation = 'relu', padding = 'same', input_shape = (28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    layers.Conv2D(10, (3, 3), activation = 'relu', padding = 'same', input_shape = (14, 14, 1)),\n",
    "    layers.AveragePooling2D(pool_size=(2,2)),\n",
    "\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(500, activation = 'relu'),\n",
    "    layers.Dense(100, activation = 'relu'),\n",
    "    layers.Dense(25, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilinga and training the model\n",
    "model.compile(optimizer='rmsprop', # I chose this because adam would not work\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "194/194 [==============================] - 45s 227ms/step - loss: 2.5805 - accuracy: 0.2274 - val_loss: 1.7894 - val_accuracy: 0.4366\n",
      "Epoch 2/10\n",
      "194/194 [==============================] - 44s 225ms/step - loss: 1.3776 - accuracy: 0.5594 - val_loss: 0.9040 - val_accuracy: 0.7036\n",
      "Epoch 3/10\n",
      "194/194 [==============================] - 44s 228ms/step - loss: 0.7497 - accuracy: 0.7490 - val_loss: 0.5787 - val_accuracy: 0.7957\n",
      "Epoch 4/10\n",
      "194/194 [==============================] - 44s 226ms/step - loss: 0.4436 - accuracy: 0.8495 - val_loss: 0.3708 - val_accuracy: 0.8682\n",
      "Epoch 5/10\n",
      "194/194 [==============================] - 44s 226ms/step - loss: 0.2908 - accuracy: 0.9027 - val_loss: 0.1995 - val_accuracy: 0.9330\n",
      "Epoch 6/10\n",
      "194/194 [==============================] - 43s 221ms/step - loss: 0.2064 - accuracy: 0.9320 - val_loss: 0.2210 - val_accuracy: 0.9188\n",
      "Epoch 7/10\n",
      "194/194 [==============================] - 45s 230ms/step - loss: 0.1545 - accuracy: 0.9476 - val_loss: 0.1408 - val_accuracy: 0.9545\n",
      "Epoch 8/10\n",
      "194/194 [==============================] - 44s 229ms/step - loss: 0.1185 - accuracy: 0.9611 - val_loss: 0.1578 - val_accuracy: 0.9483\n",
      "Epoch 9/10\n",
      "194/194 [==============================] - 43s 222ms/step - loss: 0.0937 - accuracy: 0.9684 - val_loss: 0.0682 - val_accuracy: 0.9789\n",
      "Epoch 10/10\n",
      "194/194 [==============================] - 44s 225ms/step - loss: 0.0890 - accuracy: 0.9698 - val_loss: 0.0609 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "trained_model = model.fit(train_data, epochs=10, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining some functions to be used later\n",
    "\n",
    "#model size function\n",
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "#clustering function\n",
    "def cluster_model(model, num_clust, train_images, train_labels, epochs): \n",
    "    # ---------- Defining clustering params ----------\n",
    "    cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "\n",
    "    clustering_params = {\n",
    "    'number_of_clusters': num_clust,\n",
    "    'cluster_centroids_init': tfmot.clustering.keras.CentroidInitialization.KMEANS_PLUS_PLUS,\n",
    "    'preserve_sparsity': True\n",
    "    }\n",
    "\n",
    "    # -------  Clustering --------------\n",
    "    clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "    clustered_model.compile(optimizer='rmsprop', # I chose this because adam would not work\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "    clustered_model.fit(train_images, train_labels, epochs = epochs, validation_split =0.1)\n",
    "\n",
    "    stripped_clustered_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "    # ------- Printing Summary ----------\n",
    "    clustered_model.summary()\n",
    "\n",
    "    return clustered_model, stripped_clustered_model\n",
    "\n",
    "def quantize_model(model, quant):\n",
    "\n",
    "    #-------------Quantizing------------------\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "    if quant == 16: #using float 16 if requested\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "        quantized_tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "    else: #using 8bit\n",
    "        quantized_tflite_model = converter.convert()\n",
    "        \n",
    "    # with open(f'quantized_model.tflite', 'wb') as f:\n",
    "    #     f.write(quantized_tflite_model)\n",
    "    # interpreter_quant = tf.lite.Interpreter(model_path=str(f'quantized_model.tflite'))\n",
    "    # interpreter_quant.allocate_tensors()     \n",
    "\n",
    "\n",
    "\n",
    "    return quantized_tflite_model\n",
    "\n",
    "def iterative_prune_model(model, initial_sparsity, final_sparsity, begin_step, end_step, train_images, train_labels, epochs):\n",
    "  # --------- Pruning Variable Setup ---------\n",
    "  prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "  # Define model for pruning.\n",
    "  pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
    "        final_sparsity=final_sparsity, begin_step=begin_step, end_step=end_step, frequency=100)\n",
    "  }\n",
    "\n",
    "  # ------------- Pruning Model -------------\n",
    "  pruned_model = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "  # `prune_low_magnitude` requires a recompile.\n",
    "  pruned_model.compile(optimizer='rmsprop', # I chose this because adam would not work\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "  callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  ]\n",
    "\n",
    "  pruned_model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "  # -------- Strip Pruning -------------\n",
    "  stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "  # ------- Printing Summaries ----------\n",
    "  pruned_model.summary()\n",
    "  stripped_pruned_model.summary()\n",
    "\n",
    "  return pruned_model, stripped_pruned_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#saving model\n",
    "model.save('trained_signLang_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 - 3s - loss: 0.0557 - accuracy: 0.9805 - 3s/epoch - 13ms/step\n",
      "225/225 [==============================] - 3s 13ms/step\n",
      "Model Size: 2600322.00 bytes\n",
      "Model Accuracy: 98.04796576499939 %\n",
      "Inference Time is 0.000445003258204633 s\n"
     ]
    }
   ],
   "source": [
    "#getting baseline numbers to understand model.\n",
    "model = tf.keras.models.load_model('trained_signLang_model.h5')\n",
    "\n",
    "# Evaluate prediction accuracy\n",
    "test_loss, test_acc = model.evaluate(test_images, labels_test, verbose=2)\n",
    "\n",
    "# Evaluate Inference Time\n",
    "startTime = time.time()\n",
    "prediction = model.predict(test_images)\n",
    "executionTime = (time.time() - startTime)/len(test_images)\n",
    "\n",
    "#Printing the model size and inference time and accuracy\n",
    "print(\"Model Size: %.2f bytes\" % (get_gzipped_model_size('trained_signLang_model.h5')))\n",
    "print('Model Accuracy:', test_acc*100, '%')\n",
    "print(\"Inference Time is\", executionTime, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "773/773 [==============================] - 52s 65ms/step - loss: 0.2854 - accuracy: 0.9336 - val_loss: 0.0406 - val_accuracy: 0.9927\n",
      "Epoch 2/2\n",
      "773/773 [==============================] - 50s 65ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d  (None, 28, 28, 100)       5102      \n",
      " _3 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 28, 28, 50)        90052     \n",
      " _4 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_max_po  (None, 14, 14, 50)        1         \n",
      " oling2d_1 (PruneLowMagnitu                                      \n",
      " de)                                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d  (None, 14, 14, 10)        9012      \n",
      " _5 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_averag  (None, 7, 7, 10)          1         \n",
      " e_pooling2d_1 (PruneLowMag                                      \n",
      " nitude)                                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_flatte  (None, 490)               1         \n",
      " n_1 (PruneLowMagnitude)                                         \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 500)               490502    \n",
      " 3 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 100)               100102    \n",
      " 4 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_  (None, 25)                5027      \n",
      " 5 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 699800 (2.67 MB)\n",
      "Trainable params: 350285 (1.34 MB)\n",
      "Non-trainable params: 349515 (1.33 MB)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 100)       2600      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 50)        45050     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 10)        4510      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 7, 7, 10)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 490)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 500)               245500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               50100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 25)                2525      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 350285 (1.34 MB)\n",
      "Trainable params: 350285 (1.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# first thing we will do to reduce model size is prune it\n",
    "\n",
    "# load model\n",
    "loaded_model = tf.keras.models.load_model('trained_signLang_model.h5')\n",
    "\n",
    "#variables that are to be manipulated\n",
    "initial_sparsity = 0\n",
    "final_sparsity = 0.9\n",
    "begin_step = 0\n",
    "end_step = 300\n",
    "epochs = 2\n",
    "\n",
    "#function call\n",
    "pruned_model, stripped_pruned_model = iterative_prune_model(loaded_model, initial_sparsity, final_sparsity, \n",
    "                                                            begin_step, end_step, train_images, \n",
    "                                                            labels, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#saving model\n",
    "stripped_pruned_model.save(f'stripPruned_signLang_model_{final_sparsity}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_3/kernel:0: 90.00% sparsity  (2250/2500)\n",
      "conv2d_4/kernel:0: 90.00% sparsity  (40500/45000)\n",
      "conv2d_5/kernel:0: 90.00% sparsity  (4050/4500)\n",
      "dense_3/kernel:0: 90.00% sparsity  (220500/245000)\n",
      "dense_4/kernel:0: 90.00% sparsity  (45000/50000)\n",
      "dense_5/kernel:0: 90.00% sparsity  (2250/2500)\n"
     ]
    }
   ],
   "source": [
    "def print_model_weights_sparsity(model):\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
    "            weights = layer.trainable_weights\n",
    "        else:\n",
    "            weights = layer.weights\n",
    "        for weight in weights:\n",
    "            if \"kernel\" not in weight.name or \"centroid\" in weight.name:\n",
    "                continue\n",
    "            weight_size = weight.numpy().size\n",
    "            zero_num = np.count_nonzero(weight == 0)\n",
    "            print(\n",
    "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
    "                f\"({zero_num}/{weight_size})\",\n",
    "            )\n",
    "print_model_weights_sparsity(stripped_pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 - 3s - loss: 0.2387 - accuracy: 0.9445 - 3s/epoch - 14ms/step\n",
      "225/225 [==============================] - 3s 14ms/step\n",
      "Model Size: 275290.00 bytes\n",
      "Model Accuracy: 94.45064067840576 %\n",
      "Inference Time is 0.00048677002459481916 s\n"
     ]
    }
   ],
   "source": [
    "#getting baseline numbers to understand model.\n",
    "s_model = pruned_model\n",
    "# Evaluate prediction accuracy\n",
    "test_loss, test_acc = s_model.evaluate(test_images, labels_test, verbose=2)\n",
    "\n",
    "# Evaluate Inference Time\n",
    "startTime = time.time()\n",
    "prediction = s_model.predict(test_images)\n",
    "executionTime = (time.time() - startTime)/len(test_images)\n",
    "\n",
    "#Printing the model size and inference time and accuracy\n",
    "print(\"Model Size: %.2f bytes\" % (get_gzipped_model_size(f'stripPruned_signLang_model_{final_sparsity}.h5')))\n",
    "print('Model Accuracy:', test_acc*100, '%')\n",
    "print(\"Inference Time is\", executionTime, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/2\n",
      "773/773 [==============================] - 61s 77ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 1.1800e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "773/773 [==============================] - 58s 75ms/step - loss: 6.4901e-04 - accuracy: 0.9998 - val_loss: 3.9272e-05 - val_accuracy: 1.0000\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_conv2d_3 (ClusterW  (None, 28, 28, 100)       5116      \n",
      " eights)                                                         \n",
      "                                                                 \n",
      " cluster_conv2d_4 (ClusterW  (None, 28, 28, 50)        90066     \n",
      " eights)                                                         \n",
      "                                                                 \n",
      " cluster_max_pooling2d_1 (C  (None, 14, 14, 50)        0         \n",
      " lusterWeights)                                                  \n",
      "                                                                 \n",
      " cluster_conv2d_5 (ClusterW  (None, 14, 14, 10)        9026      \n",
      " eights)                                                         \n",
      "                                                                 \n",
      " cluster_average_pooling2d_  (None, 7, 7, 10)          0         \n",
      " 1 (ClusterWeights)                                              \n",
      "                                                                 \n",
      " cluster_flatten_1 (Cluster  (None, 490)               0         \n",
      " Weights)                                                        \n",
      "                                                                 \n",
      " cluster_dense_3 (ClusterWe  (None, 500)               490516    \n",
      " ights)                                                          \n",
      "                                                                 \n",
      " cluster_dense_4 (ClusterWe  (None, 100)               100116    \n",
      " ights)                                                          \n",
      "                                                                 \n",
      " cluster_dense_5 (ClusterWe  (None, 25)                5041      \n",
      " ights)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 699881 (4.00 MB)\n",
      "Trainable params: 350381 (1.34 MB)\n",
      "Non-trainable params: 349500 (2.67 MB)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#clustering the pruned model and perserving its sparcity\n",
    "\n",
    "model = tf.keras.models.load_model(f'stripPruned_signLang_model_{final_sparsity}.h5')\n",
    "\n",
    "#defining some variables\n",
    "num_clust = 16\n",
    "\n",
    "#Function call\n",
    "clustered_model, strip_clust_model = cluster_model(model, num_clust, train_images, labels, epochs)\n",
    "\n",
    "strip_clust_model.save(f'stripClust_signLang_model_{final_sparsity}_{num_clust}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 - 4s - loss: 0.2296 - accuracy: 0.9346 - 4s/epoch - 19ms/step\n",
      "225/225 [==============================] - 5s 20ms/step\n",
      "Model Size: 70124.00 bytes\n",
      "Model Accuracy: 93.46067905426025 %\n",
      "Inference Time is 0.000670921383659333 s\n"
     ]
    }
   ],
   "source": [
    "#getting baseline numbers to understand model.\n",
    "c_model = clustered_model\n",
    "# Evaluate prediction accuracy\n",
    "test_loss, test_acc = c_model.evaluate(test_images, labels_test, verbose=2)\n",
    "\n",
    "# Evaluate Inference Time\n",
    "startTime = time.time()\n",
    "prediction = c_model.predict(test_images)\n",
    "executionTime = (time.time() - startTime)/len(test_images)\n",
    "\n",
    "#Printing the model size and inference time and accuracy\n",
    "print(\"Model Size: %.2f bytes\" % (get_gzipped_model_size(f'stripClust_signLang_model_{final_sparsity}_{num_clust}.h5')))\n",
    "print('Model Accuracy:', test_acc*100, '%')\n",
    "print(\"Inference Time is\", executionTime, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating different combinations\n",
    "\n",
    "In these graphs we will look at how different pruning and clustering levels affect inference time, size and accuracy to help us determine the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filex5bvvqv_.py\", line 71, in tf__call\n        update_mask = ag__.converted_call(ag__.ld(utils).smart_cond, (ag__.ld(training), ag__.ld(add_update), ag__.ld(no_op)), None, fscope)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filethnbw7sd.py\", line 37, in tf__smart_cond\n        ag__.if_stmt(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(pred), ag__.ld(variables).Variable), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filethnbw7sd.py\", line 33, in else_body\n        retval_ = ag__.converted_call(ag__.ld(smart_module).smart_cond, (ag__.ld(pred),), dict(true_fn=ag__.ld(true_fn), false_fn=ag__.ld(false_fn), name=ag__.ld(name)), fscope)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filex5bvvqv_.py\", line 48, in add_update\n        with ag__.ld(tf).control_dependencies([ag__.ld(self).pruning_obj.conditional_mask_update()]):\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_impl.py\", line 310, in conditional_mask_update\n        return tf.distribute.get_replica_context().merge_call(\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filet6yr7hlt.py\", line 63, in tf__mask_update_distributed\n        retval_ = ag__.converted_call(ag__.ld(tf).cond, (ag__.converted_call(ag__.ld(maybe_update_masks), (), None, fscope), ag__.ld(update_distributed), ag__.ld(no_update)), None, fscope)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filepr6m40dt.py\", line 37, in tf__maybe_update_masks\n        ag__.if_stmt(ag__.ld(self)._sparsity_m_by_n, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filepr6m40dt.py\", line 33, in else_body\n        retval_ = ag__.converted_call(ag__.ld(self)._pruning_schedule, (ag__.converted_call(ag__.ld(self)._step_fn, (), None, fscope),), None, fscope)[0]\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filen9a7fut4.py\", line 29, in tf____call__\n        sparsity = ag__.converted_call(ag__.ld(tf).math.add, (ag__.converted_call(ag__.ld(tf).math.multiply, ((ag__.ld(self).initial_sparsity - ag__.ld(self).final_sparsity), ag__.converted_call(ag__.ld(tf).math.pow, ((1 - ag__.ld(p)), ag__.ld(self).power), None, fscope)), None, fscope), ag__.ld(self).final_sparsity), dict(name='sparsity'), fscope)\n\n    TypeError: Exception encountered when calling layer 'prune_low_magnitude_conv2d_3' (type PruneLowMagnitude).\n    \n    in user code:\n    \n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py\", line 295, in add_update  *\n            with tf.control_dependencies(\n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\keras\\utils.py\", line 55, in smart_cond  *\n            pred, true_fn=true_fn, false_fn=false_fn, name=name)\n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_impl.py\", line 307, in mask_update_distributed  *\n            return tf.cond(maybe_update_masks(), update_distributed, no_update)\n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_impl.py\", line 264, in maybe_update_masks  *\n            return self._pruning_schedule(self._step_fn())[0]\n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_schedule.py\", line 238, in __call__  *\n            sparsity = tf.math.add(\n    \n        TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.\n    \n    \n    Call arguments received by layer 'prune_low_magnitude_conv2d_3' (type PruneLowMagnitude):\n      â€¢ inputs=tf.Tensor(shape=(None, 28, 28, 1), dtype=float32)\n      â€¢ training=True\n      â€¢ kwargs=<class 'inspect._empty'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#function call\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m pruned_model, stripped_pruned_model \u001b[38;5;241m=\u001b[39m \u001b[43miterative_prune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_sparsity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_sparsity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mbegin_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# ------------- Clustering --------------------\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#clustering the pruned model and perserving its sparcity\u001b[39;00m\n\u001b[0;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstripPruned_signLang_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_sparsity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 88\u001b[0m, in \u001b[0;36miterative_prune_model\u001b[1;34m(model, initial_sparsity, final_sparsity, begin_step, end_step, train_images, train_labels, epochs)\u001b[0m\n\u001b[0;32m     79\u001b[0m pruned_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# I chose this because adam would not work\u001b[39;00m\n\u001b[0;32m     80\u001b[0m             loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     81\u001b[0m             metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     84\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     85\u001b[0m   tfmot\u001b[38;5;241m.\u001b[39msparsity\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mUpdatePruningStep(),\n\u001b[0;32m     86\u001b[0m ]\n\u001b[1;32m---> 88\u001b[0m \u001b[43mpruned_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# -------- Strip Pruning -------------\u001b[39;00m\n\u001b[0;32m     92\u001b[0m stripped_pruned_model \u001b[38;5;241m=\u001b[39m tfmot\u001b[38;5;241m.\u001b[39msparsity\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mstrip_pruning(pruned_model)\n",
      "File \u001b[1;32mc:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_file30eecrxw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filex5bvvqv_.py:71\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, training, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m update_pruning_step \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(utils)\u001b[38;5;241m.\u001b[39msmart_cond, (ag__\u001b[38;5;241m.\u001b[39mld(training), ag__\u001b[38;5;241m.\u001b[39mld(increment_step), ag__\u001b[38;5;241m.\u001b[39mld(no_op)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     70\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39madd_update, (ag__\u001b[38;5;241m.\u001b[39mld(update_pruning_step),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 71\u001b[0m update_mask \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(utils)\u001b[38;5;241m.\u001b[39msmart_cond, (ag__\u001b[38;5;241m.\u001b[39mld(training), ag__\u001b[38;5;241m.\u001b[39mld(add_update), ag__\u001b[38;5;241m.\u001b[39mld(no_op)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     72\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39madd_update, (ag__\u001b[38;5;241m.\u001b[39mld(update_mask),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     73\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39madd_update, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mpruning_obj\u001b[38;5;241m.\u001b[39mweight_mask_op, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32mC:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filethnbw7sd.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__smart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     35\u001b[0m         do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28misinstance\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(pred), ag__\u001b[38;5;241m.\u001b[39mld(variables)\u001b[38;5;241m.\u001b[39mVariable), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[1;32mC:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filethnbw7sd.py:33\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__smart_cond.<locals>.else_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(smart_module)\u001b[38;5;241m.\u001b[39msmart_cond, (ag__\u001b[38;5;241m.\u001b[39mld(pred),), \u001b[38;5;28mdict\u001b[39m(true_fn\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(true_fn), false_fn\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(false_fn), name\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(name)), fscope)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filex5bvvqv_.py:48\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.add_update\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m retval__2 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcontrol_dependencies([ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mdebugging\u001b[38;5;241m.\u001b[39massert_greater_equal(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mpruning_step, ag__\u001b[38;5;241m.\u001b[39mld(np)\u001b[38;5;241m.\u001b[39mint64(\u001b[38;5;241m1\u001b[39m), message\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_PRUNE_CALLBACK_ERROR_MSG)]):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcontrol_dependencies([ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mpruning_obj\u001b[38;5;241m.\u001b[39mconditional_mask_update()]):\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m             do_return_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_impl.py:310\u001b[0m, in \u001b[0;36mPruning.conditional_mask_update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(maybe_update_masks(), update_distributed, no_update)\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_replica_context():\n\u001b[1;32m--> 310\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_replica_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmask_update_distributed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m mask_update()\n",
      "File \u001b[1;32mC:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filet6yr7hlt.py:63\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__mask_update_distributed\u001b[1;34m(distribution)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcond, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(maybe_update_masks), (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(update_distributed), ag__\u001b[38;5;241m.\u001b[39mld(no_update)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filepr6m40dt.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__maybe_update_masks\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m         do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_sparsity_m_by_n, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval_\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[1;32mC:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filepr6m40dt.py:33\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__maybe_update_masks.<locals>.else_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_pruning_schedule, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_step_fn, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filen9a7fut4.py:29\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolynomial_decay_pruning_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     28\u001b[0m     p \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mminimum, (\u001b[38;5;241m1.0\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mmaximum, (\u001b[38;5;241m0.0\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(divide), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mcast, ((ag__\u001b[38;5;241m.\u001b[39mld(step) \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mbegin_step), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mend_step \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mbegin_step)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 29\u001b[0m     sparsity \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39madd, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mmultiply, ((ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39minitial_sparsity \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfinal_sparsity), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mpow, ((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(p)), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mpower), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfinal_sparsity), \u001b[38;5;28mdict\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparsity\u001b[39m\u001b[38;5;124m'\u001b[39m), fscope)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filex5bvvqv_.py\", line 71, in tf__call\n        update_mask = ag__.converted_call(ag__.ld(utils).smart_cond, (ag__.ld(training), ag__.ld(add_update), ag__.ld(no_op)), None, fscope)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filethnbw7sd.py\", line 37, in tf__smart_cond\n        ag__.if_stmt(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(pred), ag__.ld(variables).Variable), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filethnbw7sd.py\", line 33, in else_body\n        retval_ = ag__.converted_call(ag__.ld(smart_module).smart_cond, (ag__.ld(pred),), dict(true_fn=ag__.ld(true_fn), false_fn=ag__.ld(false_fn), name=ag__.ld(name)), fscope)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filex5bvvqv_.py\", line 48, in add_update\n        with ag__.ld(tf).control_dependencies([ag__.ld(self).pruning_obj.conditional_mask_update()]):\n    File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_impl.py\", line 310, in conditional_mask_update\n        return tf.distribute.get_replica_context().merge_call(\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filet6yr7hlt.py\", line 63, in tf__mask_update_distributed\n        retval_ = ag__.converted_call(ag__.ld(tf).cond, (ag__.converted_call(ag__.ld(maybe_update_masks), (), None, fscope), ag__.ld(update_distributed), ag__.ld(no_update)), None, fscope)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filepr6m40dt.py\", line 37, in tf__maybe_update_masks\n        ag__.if_stmt(ag__.ld(self)._sparsity_m_by_n, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filepr6m40dt.py\", line 33, in else_body\n        retval_ = ag__.converted_call(ag__.ld(self)._pruning_schedule, (ag__.converted_call(ag__.ld(self)._step_fn, (), None, fscope),), None, fscope)[0]\n    File \"C:\\Users\\MAXWEL~1\\AppData\\Local\\Temp\\__autograph_generated_filen9a7fut4.py\", line 29, in tf____call__\n        sparsity = ag__.converted_call(ag__.ld(tf).math.add, (ag__.converted_call(ag__.ld(tf).math.multiply, ((ag__.ld(self).initial_sparsity - ag__.ld(self).final_sparsity), ag__.converted_call(ag__.ld(tf).math.pow, ((1 - ag__.ld(p)), ag__.ld(self).power), None, fscope)), None, fscope), ag__.ld(self).final_sparsity), dict(name='sparsity'), fscope)\n\n    TypeError: Exception encountered when calling layer 'prune_low_magnitude_conv2d_3' (type PruneLowMagnitude).\n    \n    in user code:\n    \n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py\", line 295, in add_update  *\n            with tf.control_dependencies(\n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\keras\\utils.py\", line 55, in smart_cond  *\n            pred, true_fn=true_fn, false_fn=false_fn, name=name)\n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_impl.py\", line 307, in mask_update_distributed  *\n            return tf.cond(maybe_update_masks(), update_distributed, no_update)\n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_impl.py\", line 264, in maybe_update_masks  *\n            return self._pruning_schedule(self._step_fn())[0]\n        File \"c:\\Users\\Maxwell Norris\\.conda\\envs\\ensf-ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_schedule.py\", line 238, in __call__  *\n            sparsity = tf.math.add(\n    \n        TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.\n    \n    \n    Call arguments received by layer 'prune_low_magnitude_conv2d_3' (type PruneLowMagnitude):\n      â€¢ inputs=tf.Tensor(shape=(None, 28, 28, 1), dtype=float32)\n      â€¢ training=True\n      â€¢ kwargs=<class 'inspect._empty'>\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame as df\n",
    "\n",
    "prunes = [0,0.1,0.5,0.75,0.9,0.95]\n",
    "clusters = [4,8,16,32]\n",
    "metrics = df(columns=['%Prune','Clusters','Accuracy','Size',\"Time\"])\n",
    "\n",
    "for i in prunes:\n",
    "    for j in clusters:\n",
    "        # ------------- Prunining --------------------\n",
    "        # load model\n",
    "        loaded_model = tf.keras.models.load_model('trained_signLang_model.h5')\n",
    "\n",
    "        #variables that are to be manipulated\n",
    "        initial_sparsity = 0\n",
    "        final_sparsity = i\n",
    "        begin_step = 0\n",
    "        end_step = 300\n",
    "        epochs = 2\n",
    "\n",
    "        #function call\n",
    "        pruned_model, stripped_pruned_model = iterative_prune_model(loaded_model, initial_sparsity, final_sparsity, \n",
    "                                                                    begin_step, end_step, train_images, \n",
    "                                                                    labels, epochs)\n",
    "        \n",
    "        # ------------- Clustering --------------------\n",
    "        \n",
    "        #clustering the pruned model and perserving its sparcity\n",
    "\n",
    "        model = tf.keras.models.load_model(f'stripPruned_signLang_model_{final_sparsity}.h5')\n",
    "\n",
    "        #defining some variables\n",
    "        num_clust = j\n",
    "\n",
    "        #Function call\n",
    "        clustered_model, strip_clust_model = cluster_model(model, num_clust, train_images, labels, epochs)\n",
    "\n",
    "        strip_clust_model.save(f'stripClust_signLang_model_{final_sparsity}_{num_clust}.h5')\n",
    "\n",
    "        # ----------------- Evaluating -----------------\n",
    "        c_model = clustered_model\n",
    "\n",
    "        # Evaluate prediction accuracy\n",
    "        test_loss, test_acc = c_model.evaluate(test_images, labels_test, verbose=2)\n",
    "\n",
    "        # Evaluate Inference Time\n",
    "        startTime = time.time()\n",
    "        prediction = c_model.predict(test_images)\n",
    "        executionTime = (time.time() - startTime)/len(test_images)\n",
    "\n",
    "        \n",
    "        metrics.loc[len(metrics)]=[str(i),str(j),test_acc*100,\n",
    "                                   get_gzipped_model_size(f'stripClust_signLang_model_{final_sparsity}_{num_clust}.h5'),\n",
    "                                   executionTime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphing the data created in the cell above\n",
    "val=[0.0,1.0,2.0,3.0]\n",
    "val2=[0.2,1.2,2.2,3.2]\n",
    "val3=[-0.2,0.8,1.8,2.8]\n",
    "text=['0','10','50','90']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "fig.tight_layout(pad=2)\n",
    "fig.set_size_inches(8, 12)\n",
    "ax1.bar(val2, metrics.iloc[::3,2], label='None', width=0.2)\n",
    "ax1.bar(val, metrics.iloc[1::3,2], label='8Bit', width=0.2)\n",
    "ax1.bar(val3, metrics.iloc[2::3,2], label='fp16', width=0.2)\n",
    "ax1.set_title(\"Accuracy\")\n",
    "ax1.set_xlabel(\"Percent Pruned\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_ylim([0.9,1.0])\n",
    "ax1.set_xticks(val)\n",
    "ax1.set_xticklabels(text)\n",
    "ax1.legend()\n",
    "ax2.bar(val2, metrics.iloc[::3,3], label='None', width=0.2)\n",
    "ax2.bar(val, metrics.iloc[1::3,3], label='8Bit', width=0.2)\n",
    "ax2.bar(val3, metrics.iloc[2::3,3], label='fp16', width=0.2)\n",
    "ax2.set_title(\"Size\")\n",
    "ax2.set_xlabel(\"Percent Pruned\")\n",
    "ax2.set_ylabel(\"bytes\")\n",
    "ax2.set_xticks(val)\n",
    "ax2.set_xticklabels(text)\n",
    "ax2.legend()\n",
    "ax3.bar(val2, metrics.iloc[::3,4], label='None', width=0.2)\n",
    "ax3.bar(val, metrics.iloc[1::3,4], label='8Bit', width=0.2)\n",
    "ax3.bar(val3, metrics.iloc[2::3,4], label='fp16', width=0.2)\n",
    "ax3.set_title(\"Time\")\n",
    "ax3.set_xlabel(\"Percent Pruned\")\n",
    "ax3.set_ylabel(\"Inference Time\")\n",
    "ax3.set_xticks(val)\n",
    "ax3.set_xticklabels(text)\n",
    "ax3.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model metrics calculations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensf-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
