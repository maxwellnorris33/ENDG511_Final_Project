{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some stuff, not sure what we will need yet\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading Training CSV data\n",
    "train=pd.read_csv(\"sign_mnist_train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>138</td>\n",
       "      <td>148</td>\n",
       "      <td>127</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>96</td>\n",
       "      <td>106</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>128</td>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>104</td>\n",
       "      <td>194</td>\n",
       "      <td>183</td>\n",
       "      <td>186</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "      <td>135</td>\n",
       "      <td>143</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>166</td>\n",
       "      <td>242</td>\n",
       "      <td>227</td>\n",
       "      <td>230</td>\n",
       "      <td>227</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "      <td>209</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>248</td>\n",
       "      <td>247</td>\n",
       "      <td>248</td>\n",
       "      <td>253</td>\n",
       "      <td>236</td>\n",
       "      <td>230</td>\n",
       "      <td>240</td>\n",
       "      <td>253</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>191</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>199</td>\n",
       "      <td>201</td>\n",
       "      <td>202</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      6     149     149     150     150     150     151     151     150   \n",
       "1      5     126     128     131     132     133     134     135     135   \n",
       "2     10      85      88      92      96     105     123     135     143   \n",
       "3      0     203     205     207     206     207     209     210     209   \n",
       "4      3     188     191     193     195     199     201     202     203   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     151  ...       138       148       127        89        82        96   \n",
       "1     136  ...        47       104       194       183       186       184   \n",
       "2     147  ...        68       166       242       227       230       227   \n",
       "3     210  ...       154       248       247       248       253       236   \n",
       "4     203  ...        26        40        64        48        29        46   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       106       112       120       107  \n",
       "1       184       184       182       180  \n",
       "2       226       225       224       222  \n",
       "3       230       240       253       255  \n",
       "4        49        46        46        53  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading Testing CSV data\n",
    "test=pd.read_csv(\"sign_mnist_test.csv\")\n",
    "print(train.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we must seperate the labels from the data\n",
    "label_train=train[\"label\"]\n",
    "label_test=test[\"label\"]\n",
    "\n",
    "img_train=train.drop(['label'],axis=1)\n",
    "img_test=test.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing what a random image looks like in the dataset to ensure accuracy\n",
    "sampImg = random.randint(0,len(img_train.index))\n",
    "fig, ax = plt.subplots()\n",
    "i=img_train.iloc[sampImg].to_numpy()\n",
    "i=i.reshape((28,28))\n",
    "ax.imshow(i, cmap = 'gray')\n",
    "ax.set_xlabel(label_train.iloc[sampImg])\n",
    "plt.show()\n",
    "\n",
    "#A=0\n",
    "#B=1\n",
    "#C=2\n",
    "#etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the image data into a MNIST type format\n",
    "train_images = img_train.values.reshape(-1,28,28,1)\n",
    "test_images = img_test.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing label data\n",
    "labels = to_categorical(label_train, num_classes = 25)\n",
    "labels_test = to_categorical(label_test, num_classes = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (24709, 28, 28, 1)\n",
      "x_test shape (2746, 28, 28, 1)\n",
      "y_train shape (24709, 25)\n",
      "y_test shape (2746, 25)\n"
     ]
    }
   ],
   "source": [
    "#splitting training data to such that we can use the validation dataset for post model metrics lice confusion matrix\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_images, labels, test_size=0.10, random_state=69)\n",
    "\n",
    "print(\"x_train shape\",X_train.shape)\n",
    "print(\"x_test shape\",X_val.shape)\n",
    "print(\"y_train shape\",Y_train.shape)\n",
    "print(\"y_test shape\",Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating more data using image data generator (this will be used late, just setting it up)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1\n",
    ")\n",
    "\n",
    "train_data = datagen.flow(X_train, Y_train, batch_size = 128)\n",
    "test_data = datagen.flow(X_val, Y_val, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 100)       2600      \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 50)        45050     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 10)        4510      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 7, 7, 10)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 490)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 500)               245500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               50100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 25)                2525      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 350285 (1.34 MB)\n",
      "Trainable params: 350285 (1.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture.\n",
    "model = tf.keras.models.Sequential([\n",
    "    layers.Conv2D(100, (5, 5), activation = 'relu', padding = 'same', input_shape = (28, 28, 1)),\n",
    "    layers.Conv2D(50, (3, 3), activation = 'relu', padding = 'same', input_shape = (28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    layers.Conv2D(10, (3, 3), activation = 'relu', padding = 'same', input_shape = (14, 14, 1)),\n",
    "    layers.AveragePooling2D(pool_size=(2,2)),\n",
    "\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(500, activation = 'relu'),\n",
    "    layers.Dense(100, activation = 'relu'),\n",
    "    layers.Dense(25, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilinga and training the model\n",
    "model.compile(optimizer='rmsprop', # I chose this because adam would not work\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "194/194 [==============================] - 41s 211ms/step - loss: 2.6791 - accuracy: 0.1986 - val_loss: 2.2518 - val_accuracy: 0.3077\n",
      "Epoch 2/10\n",
      "194/194 [==============================] - 41s 210ms/step - loss: 1.4994 - accuracy: 0.5158 - val_loss: 1.0393 - val_accuracy: 0.6551\n",
      "Epoch 3/10\n",
      "194/194 [==============================] - 41s 212ms/step - loss: 0.8357 - accuracy: 0.7199 - val_loss: 0.5708 - val_accuracy: 0.8084\n",
      "Epoch 4/10\n",
      "194/194 [==============================] - 42s 219ms/step - loss: 0.5126 - accuracy: 0.8271 - val_loss: 0.3514 - val_accuracy: 0.8857\n",
      "Epoch 5/10\n",
      "194/194 [==============================] - 52s 269ms/step - loss: 0.3174 - accuracy: 0.8922 - val_loss: 0.2339 - val_accuracy: 0.9235\n",
      "Epoch 6/10\n",
      "194/194 [==============================] - 46s 238ms/step - loss: 0.2303 - accuracy: 0.9236 - val_loss: 0.2308 - val_accuracy: 0.9217\n",
      "Epoch 7/10\n",
      "194/194 [==============================] - 47s 242ms/step - loss: 0.1645 - accuracy: 0.9446 - val_loss: 0.1494 - val_accuracy: 0.9501\n",
      "Epoch 8/10\n",
      "194/194 [==============================] - 46s 237ms/step - loss: 0.1237 - accuracy: 0.9587 - val_loss: 0.0989 - val_accuracy: 0.9658\n",
      "Epoch 9/10\n",
      "194/194 [==============================] - 46s 239ms/step - loss: 0.1004 - accuracy: 0.9658 - val_loss: 0.1438 - val_accuracy: 0.9527\n",
      "Epoch 10/10\n",
      "194/194 [==============================] - 46s 235ms/step - loss: 0.0812 - accuracy: 0.9722 - val_loss: 0.0661 - val_accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "trained_model = model.fit(train_data, epochs=10, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining some functions to be used later\n",
    "\n",
    "#model size function\n",
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "#clustering function\n",
    "def cluster_model(model, num_clust, cent_init, train_images, train_labels, learn_rate, epochs): \n",
    "    # ---------- Defining clustering params ----------\n",
    "    cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "\n",
    "    clustering_params = {\n",
    "    'number_of_clusters': num_clust,\n",
    "    'cluster_centroids_init': cent_init\n",
    "    }\n",
    "\n",
    "    # -------  Clustering --------------\n",
    "    clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "    # Use smaller learning rate for fine-tuning clustered model\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "\n",
    "    clustered_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "    clustered_model.fit(train_images, train_labels, epochs = epochs, validation_split =0.1)\n",
    "\n",
    "    # ------- Printing Summary ----------\n",
    "    clustered_model.summary()\n",
    "\n",
    "    return clustered_model\n",
    "\n",
    "def quantize_model(model, quant):\n",
    "\n",
    "    #-------------Quantizing------------------\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "    if quant == 16: #using float 16 if requested\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "        quantized_tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "    else: #using 8bit\n",
    "        quantized_tflite_model = converter.convert()\n",
    "        \n",
    "    # with open(f'quantized_model.tflite', 'wb') as f:\n",
    "    #     f.write(quantized_tflite_model)\n",
    "    # interpreter_quant = tf.lite.Interpreter(model_path=str(f'quantized_model.tflite'))\n",
    "    # interpreter_quant.allocate_tensors()     \n",
    "\n",
    "    # ------- Printing Summary ----------\n",
    "    quantized_tflite_model.summary()\n",
    "\n",
    "    return quantized_tflite_model\n",
    "\n",
    "def iterative_prune_model(model, initial_sparsity, final_sparsity, begin_step, end_step, train_images, train_labels, epochs):\n",
    "  # --------- Pruning Variable Setup ---------\n",
    "  prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "  # Define model for pruning.\n",
    "  pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
    "        final_sparsity=final_sparsity, begin_step=begin_step, end_step=end_step, frequency=100)\n",
    "  }\n",
    "\n",
    "  # ------------- Pruning Model -------------\n",
    "  pruned_model = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "  # `prune_low_magnitude` requires a recompile.\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "  pruned_model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  ]\n",
    "\n",
    "  pruned_model.fit(train_images, train_labels, epochs=epochs, validation_split=0.1,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "  # -------- Strip Pruning -------------\n",
    "  stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "  # ------- Printing Summaries ----------\n",
    "  pruned_model.summary()\n",
    "  stripped_pruned_model.summary()\n",
    "\n",
    "  return pruned_model, stripped_pruned_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "model.save('untrained_signLang_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting baseline numbers to understand model.\n",
    "\n",
    "# Evaluate prediction accuracy\n",
    "test_loss, test_acc = trained_model.evaluate(test_images, labels_test, verbose=2)\n",
    "\n",
    "# Evaluate Inference Time\n",
    "startTime = time.time()\n",
    "prediction = model.predict(test_images)\n",
    "executionTime = (time.time() - startTime)/len(test_images)\n",
    "\n",
    "#Printing the model size and inference time and accuracy\n",
    "print(\"Model Size: %.2f bytes\" % (get_gzipped_model_size('untrained_signLang_model.h5')))\n",
    "print('Model Accuracy:', test_acc*100, '%')\n",
    "print(\"Inference Time is\", executionTime, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first thing we will do to reduce model size is prune it\n",
    "\n",
    "#variables that are to be manipulated\n",
    "initial_sparsity = 0.1\n",
    "final_sparsity = 0.7\n",
    "begin_step = 0\n",
    "end_step = 100\n",
    "epochs = 5\n",
    "\n",
    "#function call\n",
    "pruned_model, stripped_pruned_model = iterative_prune_model(trained_model, initial_sparsity, final_sparsity, \n",
    "                                                            begin_step, end_step, train_images, \n",
    "                                                            labels, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will quantize the pruned model\n",
    "\n",
    "#Defining some new variables\n",
    "\n",
    "\n",
    "#sp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensf-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
